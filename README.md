The following collection is meant to serve as a reference for engineers, data scientists, and others making decisions about building technological solutions for real-world problems. Hopefully, this will help us avoid repeating mistakes of the past by informing the design of new systems or the decision not to build a technological solution at all.

This is a living document, so please send suggestions for additions through "Issues" or feel free to send pull requests. If you find any other problems with links or the articles themselves, please also open an "Issue".

# Fairness

## Lending & Credit approval

- [Gender Bias Complaints against Apple Card Signal a Dark Side to Fintech](https://hbswk.hbs.edu/item/gender-bias-complaints-against-apple-card-signal-a-dark-side-to-fintech)
- [Exploring Racial Discrimination in Mortgage Lending: A Call for Greater Transparency](https://listwithclever.com/real-estate-blog/racial-discrimination-in-mortgage-lending/)

## Hiring

- [Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G)

## Employee evaluation

- [Houston Schools Must Face Teacher Evaluation Lawsuit](https://www.courthousenews.com/houston-schools-must-face-teacher-evaluation-lawsuit/)

## Pre-trial risk assessment and criminal sentencing

- COMPAS:
    - [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
    - [How We Analyzed the COMPAS Recidivism Algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)
    - [GitHub repository for COMPAS analysis](https://github.com/propublica/compas-analysis)
    - [Can you make AI fairer than a judge? Play our courtroom algorithm game](https://www.technologyreview.com/s/613508/ai-fairer-than-judge-criminal-risk-assessment-algorithm/)
    
## Predictive Policing & Other Law Enforcement Use Cases

- [Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice](https://www.nyulawreview.org/online-features/dirty-data-bad-predictions-how-civil-rights-violations-impact-police-data-predictive-policing-systems-and-justice/)
- [Amazon’s Face Recognition Falsely Matched 28 Members of Congress With Mugshots](https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28)
- [The Perpetual Line-Up - Unregulated police face recognition in America](https://www.perpetuallineup.org/)
- [Stuck in a Pattern: Early evidence on "predictive policing" and civil rights](https://www.upturn.org/reports/2016/stuck-in-a-pattern/)
- [Crime-prediction tool PredPol amplifies racially biased policing, study shows](https://www.mic.com/articles/156286/crime-prediction-tool-pred-pol-only-amplifies-racially-biased-policing-study-shows#.DZeqQ4LYs)

## Admissions

- [British Medical Journal: A blot on the profession](https://www.bmj.com/content/296/6623/657)

## School Choice

- [Custom Software Helps Cities Manage School Choice](https://www.edweek.org/ew/articles/2013/12/04/13algorithm_ep.h33.html)

## Hate Speech Detection

- [Oh dear... AI models used to flag hate speech online are, er, racist against black people](https://www.theregister.co.uk/2019/10/11/ai_black_people/)
- [The Risk of Racial Bias in Hate Speech Detection](https://homes.cs.washington.edu/~msap/pdfs/sap2019risk.pdf)

## Image Labelling

- [Google Photos identified two black people as 'gorillas'](https://mashable.com/2015/07/01/google-photos-black-people-gorillas/)
- [When It Comes to Gorillas, Google Photos Remains Blind](https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/)
- [The viral selfie app ImageNet Roulette seemed fun – until it called me a racist slur](https://www.theguardian.com/technology/2019/sep/17/imagenet-roulette-asian-racist-slur-selfie)

## Public Benefits & Health

- [A health care algorithm affecting millions is biased against black patients](https://www.theverge.com/2019/10/24/20929337/care-algorithm-study-race-bias-health)
- [What happens when an algorithm cuts your health care](https://www.theverge.com/2018/3/21/17144260/healthcare-medicaid-algorithm-arkansas-cerebral-palsy)
- [China Knows How to Take Away Your Health Insurance](https://www.bloomberg.com/opinion/articles/2019-06-14/china-knows-how-to-take-away-your-health-insurance)
- [Foretelling the Future: A Critical Perspective on the Use of Predictive Analytics in Child Welfare](http://kirwaninstitute.osu.edu/wp-content/uploads/2017/05/ki-predictive-analytics.pdf)

## Ads

- [Discrimination in Online Ad Delivery](https://arxiv.org/abs/1301.6822)
- [Probing the Dark Side of Google’s Ad-Targeting System](https://www.technologyreview.com/s/539021/probing-the-dark-side-of-googles-ad-targeting-system/)
- [Facebook Engages in Housing Discrimination With Its Ad Practices, U.S. Says](https://www.nytimes.com/2019/03/28/us/politics/facebook-housing-discrimination.html)

## Search

- [Algorithms of Oppression: How Search Engines reinforce racism](http://algorithmsofoppression.com/)
- [Bias already exists in search engine results, and it’s only going to get worse](https://www.technologyreview.com/s/610275/meet-the-woman-who-searches-out-search-engines-bias-against-women-and-minorities/)
- [Truth in pictures: What Google image searches tell us about inequality at work](https://www.diversityemployers.com/blog/2017/05/truth-in-pictures-what-google-image-searches-tell-us-about-inequality-at-work/)

## Translations

- [Google Translate might have a gender problem](https://mashable.com/2017/11/30/google-translate-sexism/)

## Jury Selection

- [The Big Data Jury](https://scholarship.law.nd.edu/ndlr/vol91/iss3/2/)

# Safety

## Self-driving cars

- [Remember the Uber self-driving car that killed a woman crossing the street? The AI had no clue about jaywalkers](https://www.theregister.co.uk/2019/11/06/uber_self_driving_car_death/)

# Privacy

- [Privacy Attacks on Machine Learning Models](https://www.infoq.com/articles/privacy-attacks-machine-learning-models/)
